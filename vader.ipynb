{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGpBzgdaWF9E6qnlb7B4yQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stillrahim/jupyter-exploration/blob/main/vader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRcsg-1yjs3k"
      },
      "outputs": [],
      "source": [
        "# Run this first in Colab / local notebook\n",
        "!pip install vaderSentiment textblob scikit-learn librosa soundfile transformers torchaudio matplotlib seaborn pandas nltk\n",
        "\n",
        "# NLTK download for some tokenizers/stopwords if needed\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example small dataset for demonstration (replace with class dataset)\n",
        "data = [\n",
        "  {\"text\":\"I love this product, it's fantastic!\", \"label\":\"positive\"},\n",
        "  {\"text\":\"This was the worst service ever, I'm disappointed.\", \"label\":\"negative\"},\n",
        "  {\"text\":\"I suppose it's okay, nothing special.\", \"label\":\"neutral\"}\n",
        "]\n",
        "df = pd.DataFrame(data)\n",
        "df\n"
      ],
      "metadata": {
        "id": "eoheXJBfjt4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from textblob import TextBlob\n",
        "\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "def vader_label(text):\n",
        "    s = analyzer.polarity_scores(text)['compound']\n",
        "    if s >= 0.05: return 'positive'\n",
        "    if s <= -0.05: return 'negative'\n",
        "    return 'neutral'\n",
        "\n",
        "def textblob_label(text):\n",
        "    b = TextBlob(text).sentiment.polarity\n",
        "    if b > 0.05: return 'positive'\n",
        "    if b < -0.05: return 'negative'\n",
        "    return 'neutral'\n",
        "\n",
        "df['vader'] = df['text'].apply(vader_label)\n",
        "df['textblob'] = df['text'].apply(textblob_label)\n",
        "df\n"
      ],
      "metadata": {
        "id": "887edSo7jv3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(\"VADER vs truth\")\n",
        "print(classification_report(df['label'], df['vader']))\n",
        "print(\"TextBlob vs truth\")\n",
        "print(classification_report(df['label'], df['textblob']))\n"
      ],
      "metadata": {
        "id": "aMNuVhVBjyYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you have a CSV with columns text,label, load it:\n",
        "# df = pd.read_csv('/path/to/emotion_dataset.csv')\n",
        "\n",
        "# For demo, reuse df but expand it in practice\n",
        "df_ml = df.copy()\n"
      ],
      "metadata": {
        "id": "SnrxOqtRj0pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_ml['text'], df_ml['label'], test_size=0.3, random_state=42)\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(ngram_range=(1,2), stop_words='english')),\n",
        "    ('clf', LinearSVC())\n",
        "])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "y_pred = pipe.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "YSj-RNKpj21-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally: use sentence-transformers for embeddings (install first)\n",
        "!pip install -q sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "emb_model = SentenceTransformer('all-MiniLM-L6-v2')  # small, fast\n",
        "\n",
        "X_emb = emb_model.encode(df_ml['text'].tolist())\n",
        "# split and train a simple classifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X_emb, df_ml['label'], test_size=0.3, random_state=42)\n",
        "clf = LogisticRegression(max_iter=1000).fit(X_tr, y_tr)\n",
        "print(classification_report(y_te, clf.predict(X_te)))\n"
      ],
      "metadata": {
        "id": "caV6wGQvj4Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "# Example: load one audio file (replace with actual path)\n",
        "audio_path = '/content/sample.wav'  # upload a sample or provide link\n",
        "y, sr = librosa.load(audio_path, sr=16000)\n",
        "\n",
        "# Extract features: MFCC, chroma, zcr, spectral centroid\n",
        "mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "mfcc_mean = mfcc.mean(axis=1)\n",
        "zcr = librosa.feature.zero_crossing_rate(y).mean()\n",
        "centroid = librosa.feature.spectral_centroid(y=y, sr=sr).mean()\n",
        "features = np.hstack([mfcc_mean, zcr, centroid])\n",
        "features.shape\n"
      ],
      "metadata": {
        "id": "Zp6BbdvWj6zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppose you prepared features X_audio (n_samples x n_features) and labels y_audio\n",
        "# For demo:\n",
        "X_audio = np.array([features])    # replace with full dataset features\n",
        "y_audio = np.array(['neutral'])   # replace with real labels\n",
        "\n",
        "# Train/test split and a small classifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Here you'd normally have many samples; this is templated code\n",
        "# X_tr, X_te, y_tr, y_te = train_test_split(X_audio, y_audio, test_size=0.3)\n",
        "# clf_audio = RandomForestClassifier().fit(X_tr, y_tr)\n",
        "# print(classification_report(y_te, clf_audio.predict(X_te)))\n"
      ],
      "metadata": {
        "id": "bGTX1_-Uj9js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text embedding (sentence-transformers)\n",
        "text_samples = [\"I am so happy today!\"]  # replace with dataset of transcripts\n",
        "text_emb = emb_model.encode(text_samples)  # shape (n, d_text)\n",
        "\n",
        "# audio features (use same pipeline from Part 3) -> features shape (n, d_audio)\n",
        "audio_feats = np.array([features]) # placeholder\n",
        "\n",
        "# concatenate\n",
        "X_multi = np.hstack([text_emb, audio_feats])\n",
        "\n",
        "# train a classifier\n",
        "clf_multi = LogisticRegression(max_iter=1000)\n",
        "# clf_multi.fit(X_train_multi, y_train_multi)\n",
        "# evaluate...\n"
      ],
      "metadata": {
        "id": "lTSmnpbVj-xR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Visualization 1: Confusion matrix\n",
        "# cm = confusion_matrix(y_test, y_pred)\n",
        "# sns.heatmap(cm, annot=True, fmt='d')\n",
        "# plt.title(\"Confusion Matrix\")\n",
        "# plt.xlabel(\"Predicted\")\n",
        "# plt.ylabel(\"True\")\n",
        "# plt.show()\n",
        "\n",
        "# Visualization 2: Emotion distribution pie / bar\n",
        "# counts = df['predicted_emotion'].value_counts()\n",
        "# counts.plot(kind='bar')\n",
        "# plt.title(\"Predicted Emotion Distribution\")\n",
        "# plt.xlabel(\"Emotion\")\n",
        "# plt.ylabel(\"Count\")\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "LxMBto6BkAY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick demo: VADER + librosa feature + simple rule: if vader negative and energy high -> angry\n",
        "text = \"I'm really angry about this order.\"\n",
        "v_label = vader_label(text)\n",
        "\n",
        "# audio: compute energy\n",
        "energy = np.sum(y**2) / len(y)\n",
        "print(\"VADER:\", v_label, \"Energy:\", energy)\n",
        "if v_label == 'negative' and energy > 0.01:\n",
        "    print(\"Rule-based multimodal signal: possible anger\")\n"
      ],
      "metadata": {
        "id": "Or-OwsUJkDC5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}